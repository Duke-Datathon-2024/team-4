{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b725a9b8-d5c9-4b9d-8d87-2fbe08122cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbrow51/.conda/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import torch\n",
    "# import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import Accuracy, AUROC, F1Score, Precision, Recall\n",
    "from itertools import chain\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# from transformers import RobertaTokenizerFast\n",
    "# from transformers import TFRobertaModel\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f01ac45-49f0-4368-824c-803e2887a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda...\n"
     ]
    }
   ],
   "source": [
    "# get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"using device: {device}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9414f413-874b-403e-946b-6b5ea0f5dd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff49075-f477-4329-a155-afa350808b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed set...\n"
     ]
    }
   ],
   "source": [
    "def seed_script(seed: int):\n",
    "    # set torch seed\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # set numpy seed\n",
    "    np.random.seed(seed)\n",
    "    print(\"seed set...\")\n",
    "    \n",
    "SEED = 13\n",
    "seed_script(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36472a8-ddf8-4218-93fa-04365348f4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5aeee7-e354-4a05-bf2b-31774a74855b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37988</td>\n",
       "      <td>Admission Date:  [**2166-6-5**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37282</td>\n",
       "      <td>Admission Date:  [**2109-12-23**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26313</td>\n",
       "      <td>Admission Date: [**2114-12-17**]        Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13852</td>\n",
       "      <td>Admission Date:  [**2112-5-16**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51031</td>\n",
       "      <td>Admission Date:  [**2155-2-26**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>7020</td>\n",
       "      <td>14096</td>\n",
       "      <td>Admission Date:  [**2136-5-6**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>7021</td>\n",
       "      <td>12564</td>\n",
       "      <td>Admission Date:  [**2152-2-28**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>7022</td>\n",
       "      <td>24492</td>\n",
       "      <td>Admission Date:  [**2146-2-7**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>7023</td>\n",
       "      <td>26304</td>\n",
       "      <td>Admission Date:  [**2167-2-10**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>7024</td>\n",
       "      <td>41160</td>\n",
       "      <td>Admission Date:  [**2105-4-28**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7025 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ROW_ID                                               TEXT\n",
       "0              0   37988  Admission Date:  [**2166-6-5**]              D...\n",
       "1              1   37282  Admission Date:  [**2109-12-23**]             ...\n",
       "2              2   26313  Admission Date: [**2114-12-17**]        Discha...\n",
       "3              3   13852  Admission Date:  [**2112-5-16**]              ...\n",
       "4              4   51031  Admission Date:  [**2155-2-26**]              ...\n",
       "...          ...     ...                                                ...\n",
       "7020        7020   14096  Admission Date:  [**2136-5-6**]       Discharg...\n",
       "7021        7021   12564  Admission Date:  [**2152-2-28**]       Dischar...\n",
       "7022        7022   24492  Admission Date:  [**2146-2-7**]              D...\n",
       "7023        7023   26304  Admission Date:  [**2167-2-10**]              ...\n",
       "7024        7024   41160  Admission Date:  [**2105-4-28**]              ...\n",
       "\n",
       "[7025 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle data import here\n",
    "train_notes_df = pd.read_csv(\"./data/df_notes.csv\")\n",
    "train_notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adcc21e8-3093-4ce5-b1b5-32482e327e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>sdoh_community_present</th>\n",
       "      <th>sdoh_community_absent</th>\n",
       "      <th>sdoh_education</th>\n",
       "      <th>sdoh_economics</th>\n",
       "      <th>sdoh_environment</th>\n",
       "      <th>behavior_alcohol</th>\n",
       "      <th>behavior_tobacco</th>\n",
       "      <th>behavior_drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>328</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>58064</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>58873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>58947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>58624</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>59236</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7025 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id  sdoh_community_present  sdoh_community_absent  sdoh_education  \\\n",
       "0          5                       0                      0               0   \n",
       "1         42                       0                      0               0   \n",
       "2        136                       1                      0               0   \n",
       "3        442                       1                      1               0   \n",
       "4        328                       1                      0               0   \n",
       "...      ...                     ...                    ...             ...   \n",
       "7020   58064                       1                      0               1   \n",
       "7021   58873                       1                      0               0   \n",
       "7022   58947                       1                      0               1   \n",
       "7023   58624                       1                      0               0   \n",
       "7024   59236                       1                      0               0   \n",
       "\n",
       "      sdoh_economics  sdoh_environment  behavior_alcohol  behavior_tobacco  \\\n",
       "0                  0                 0                 0                 1   \n",
       "1                  0                 0                 0                 2   \n",
       "2                  2                 1                 3                 4   \n",
       "3                  0                 1                 3                 1   \n",
       "4                  2                 1                 3                 3   \n",
       "...              ...               ...               ...               ...   \n",
       "7020               1                 1                 0                 0   \n",
       "7021               0                 1                 3                 3   \n",
       "7022               2                 2                 0                 0   \n",
       "7023               1                 0                 1                 2   \n",
       "7024               2                 1                 4                 2   \n",
       "\n",
       "      behavior_drug  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 2  \n",
       "4                 3  \n",
       "...             ...  \n",
       "7020              0  \n",
       "7021              3  \n",
       "7022              0  \n",
       "7023              0  \n",
       "7024              2  \n",
       "\n",
       "[7025 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ann_url = 'https://raw.githubusercontent.com/hibaahsan/MIMIC-SBDH/main/MIMIC-SBDH.csv'\n",
    "\n",
    "train_ann_df = pd.read_csv(train_ann_url)\n",
    "train_ann_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a9677d-e9b4-4532-9e28-4b6e8660a20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2333969/13417565.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0 1 0 ... 1 0 0]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  train_set_df.loc[:, 'community_binary'] = train_set_df.loc[:, 'community_binary'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# use alcohol, \n",
    "alcohol_level_dict = {\n",
    "    0: 0, \n",
    "    1: 1, \n",
    "    2: 1, \n",
    "    3: 1, \n",
    "    4: 1\n",
    "}\n",
    "\n",
    "environment_level_dict = {\n",
    "    0: 0, \n",
    "    1: 1, \n",
    "    2: 1\n",
    "}\n",
    "\n",
    "train_set_df = train_notes_df.merge(train_ann_df, left_on=\"ROW_ID\", right_on=\"row_id\")\n",
    "train_set_df\n",
    "\n",
    "# recode the levels of 'behavior_alcohol' based on the alcohol level dict\n",
    "train_set_df.loc[:, 'alcohol_binary'] = train_set_df.loc[:, 'behavior_alcohol'].map(alcohol_level_dict)\n",
    "\n",
    "# recode the levels of 'sdoh_environment' based on the environment level dict\n",
    "train_set_df.loc[:, 'environment_binary'] = train_set_df.loc[:, 'sdoh_environment'].map(environment_level_dict)\n",
    "\n",
    "# if we have documentation of community present OR absent, code the binary version as 1 else 0\n",
    "train_set_df.loc[:, 'community_binary'] = (train_set_df.sdoh_community_present == 1) | (train_set_df.sdoh_community_absent == 1)\n",
    "train_set_df.loc[:, 'community_binary'] = train_set_df.loc[:, 'community_binary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76ad9c1-6374-421d-84f4-cc41b2e9ad47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "behavior_alcohol\n",
       "3    2444\n",
       "1    2077\n",
       "0    1657\n",
       "2     515\n",
       "4     332\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df.behavior_alcohol.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4e6c61-d0f9-4dd2-b944-b83bdffb00c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sdoh_community_present  sdoh_community_absent\n",
       "1                       0                        3878\n",
       "0                       0                        2363\n",
       "1                       1                         585\n",
       "0                       1                         199\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df[['sdoh_community_present', 'sdoh_community_absent']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4756486-9580-4e90-a901-0cb182a669d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environment_binary\n",
       "1    4420\n",
       "0    2605\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df.environment_binary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb660e9f-9e67-49b1-86e0-1c7e7eeb54e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "community_binary\n",
       "1    4662\n",
       "0    2363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df.community_binary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5524b20a-ceeb-483b-959d-e4505036ecf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol_binary\n",
       "1    5368\n",
       "0    1657\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df.alcohol_binary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b754e995-a9f3-46ec-ac08-a02724155f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>row_id</th>\n",
       "      <th>sdoh_community_present</th>\n",
       "      <th>sdoh_community_absent</th>\n",
       "      <th>sdoh_education</th>\n",
       "      <th>sdoh_economics</th>\n",
       "      <th>sdoh_environment</th>\n",
       "      <th>behavior_alcohol</th>\n",
       "      <th>behavior_tobacco</th>\n",
       "      <th>behavior_drug</th>\n",
       "      <th>alcohol_binary</th>\n",
       "      <th>environment_binary</th>\n",
       "      <th>community_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37988</td>\n",
       "      <td>Admission Date:  [**2166-6-5**]              D...</td>\n",
       "      <td>37988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37282</td>\n",
       "      <td>Admission Date:  [**2109-12-23**]             ...</td>\n",
       "      <td>37282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26313</td>\n",
       "      <td>Admission Date: [**2114-12-17**]        Discha...</td>\n",
       "      <td>26313</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13852</td>\n",
       "      <td>Admission Date:  [**2112-5-16**]              ...</td>\n",
       "      <td>13852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51031</td>\n",
       "      <td>Admission Date:  [**2155-2-26**]              ...</td>\n",
       "      <td>51031</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>7020</td>\n",
       "      <td>14096</td>\n",
       "      <td>Admission Date:  [**2136-5-6**]       Discharg...</td>\n",
       "      <td>14096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>7021</td>\n",
       "      <td>12564</td>\n",
       "      <td>Admission Date:  [**2152-2-28**]       Dischar...</td>\n",
       "      <td>12564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>7022</td>\n",
       "      <td>24492</td>\n",
       "      <td>Admission Date:  [**2146-2-7**]              D...</td>\n",
       "      <td>24492</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>7023</td>\n",
       "      <td>26304</td>\n",
       "      <td>Admission Date:  [**2167-2-10**]              ...</td>\n",
       "      <td>26304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>7024</td>\n",
       "      <td>41160</td>\n",
       "      <td>Admission Date:  [**2105-4-28**]              ...</td>\n",
       "      <td>41160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7025 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ROW_ID                                               TEXT  \\\n",
       "0              0   37988  Admission Date:  [**2166-6-5**]              D...   \n",
       "1              1   37282  Admission Date:  [**2109-12-23**]             ...   \n",
       "2              2   26313  Admission Date: [**2114-12-17**]        Discha...   \n",
       "3              3   13852  Admission Date:  [**2112-5-16**]              ...   \n",
       "4              4   51031  Admission Date:  [**2155-2-26**]              ...   \n",
       "...          ...     ...                                                ...   \n",
       "7020        7020   14096  Admission Date:  [**2136-5-6**]       Discharg...   \n",
       "7021        7021   12564  Admission Date:  [**2152-2-28**]       Dischar...   \n",
       "7022        7022   24492  Admission Date:  [**2146-2-7**]              D...   \n",
       "7023        7023   26304  Admission Date:  [**2167-2-10**]              ...   \n",
       "7024        7024   41160  Admission Date:  [**2105-4-28**]              ...   \n",
       "\n",
       "      row_id  sdoh_community_present  sdoh_community_absent  sdoh_education  \\\n",
       "0      37988                       0                      0               0   \n",
       "1      37282                       1                      1               0   \n",
       "2      26313                       0                      0               0   \n",
       "3      13852                       0                      0               0   \n",
       "4      51031                       1                      1               0   \n",
       "...      ...                     ...                    ...             ...   \n",
       "7020   14096                       1                      0               0   \n",
       "7021   12564                       0                      0               0   \n",
       "7022   24492                       1                      0               0   \n",
       "7023   26304                       0                      0               0   \n",
       "7024   41160                       0                      0               0   \n",
       "\n",
       "      sdoh_economics  sdoh_environment  behavior_alcohol  behavior_tobacco  \\\n",
       "0                  0                 1                 2                 3   \n",
       "1                  1                 0                 2                 0   \n",
       "2                  0                 0                 3                 2   \n",
       "3                  0                 0                 1                 0   \n",
       "4                  0                 1                 0                 0   \n",
       "...              ...               ...               ...               ...   \n",
       "7020               0                 1                 3                 3   \n",
       "7021               0                 0                 0                 2   \n",
       "7022               2                 1                 1                 1   \n",
       "7023               0                 0                 1                 2   \n",
       "7024               1                 0                 0                 0   \n",
       "\n",
       "      behavior_drug  alcohol_binary  environment_binary  community_binary  \n",
       "0                 0               1                   1                 0  \n",
       "1                 0               1                   0                 1  \n",
       "2                 0               1                   0                 0  \n",
       "3                 0               1                   0                 0  \n",
       "4                 0               0                   1                 1  \n",
       "...             ...             ...                 ...               ...  \n",
       "7020              0               1                   1                 1  \n",
       "7021              0               0                   0                 0  \n",
       "7022              2               1                   1                 1  \n",
       "7023              3               1                   0                 0  \n",
       "7024              0               0                   0                 0  \n",
       "\n",
       "[7025 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad084583-b1a4-439e-a9e6-63836edc9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70/15/15 split\n",
    "# perform a split on the idxs stratified by the target classes\n",
    "# to make sure we have an even class distribution\n",
    "train_df, val_test_df = train_test_split(\n",
    "    train_set_df,\n",
    "    test_size=0.3,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    val_test_df,\n",
    "    test_size=0.5,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c3ef5f-f50b-49ea-a21f-5ca6ef2563f1",
   "metadata": {},
   "source": [
    "## Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc6d2e2e-b8ae-47f1-9fd3-a784222fe215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class FrameParams:\n",
    "#     df: pd.DataFrame\n",
    "#     class_name: str\n",
    "#     class_val: float\n",
    "\n",
    "\n",
    "# # function to get the set of unique patient ids in the dataframe\n",
    "# # then split based on the train/val/test proportion\n",
    "# def split_ids(id_col, test_prop, validation, seed):\n",
    "#     # get set of unique ids and convert to a list\n",
    "#     id_list = list(set(id_col))\n",
    "\n",
    "#     # shuffle id list\n",
    "#     random.Random(seed).shuffle(id_list)\n",
    "\n",
    "#     # get split lengths\n",
    "#     id_list_len = len(id_list)\n",
    "\n",
    "#     # get the length of indexes to add to the train/test sets\n",
    "#     train_prop = 1.0 - (2 * test_prop)\n",
    "#     train_len = int(train_prop * id_list_len)\n",
    "#     test_len = int(test_prop * id_list_len)\n",
    "\n",
    "#     # index set ids\n",
    "#     if validation:\n",
    "#         train_ids = id_list[:train_len]\n",
    "#         val_ids = id_list[train_len:train_len+test_len]\n",
    "\n",
    "#     else:\n",
    "#         train_ids = id_list[:train_len+test_len]\n",
    "#         val_ids = None\n",
    "\n",
    "#     test_ids = id_list[train_len+test_len:]\n",
    "\n",
    "#     print('total ids:', id_list_len)\n",
    "\n",
    "#     print('train ids: {}, prop: {:.3f}'.format(\n",
    "#         len(train_ids),\n",
    "#         len(train_ids) / id_list_len\n",
    "#     ))\n",
    "\n",
    "#     if validation:\n",
    "#         print('val ids: {}, prop: {:.3f}'.format(\n",
    "#             len(val_ids),\n",
    "#             len(val_ids) / id_list_len\n",
    "#         ))\n",
    "\n",
    "#     print('test ids: {}, prop: {:.3f}\\n'.format(\n",
    "#         len(test_ids),\n",
    "#         len(test_ids) / id_list_len\n",
    "#     ))\n",
    "\n",
    "#     return train_ids, val_ids, test_ids\n",
    "\n",
    "# # function to index pos/neg dataframes by set patient ids and merge them\n",
    "# def index_dataframes(df_obj_list, ids, id_var):\n",
    "#     # zip pos/neg dataframes and ids\n",
    "#     components = zip([df_obj.df for df_obj in df_obj_list], ids)\n",
    "\n",
    "#     # index dataframes by ids for pos/neg\n",
    "#     df_list = [df[df[id_var].isin(ids)] for df, ids in components]\n",
    "\n",
    "#     # merge pos/neg dataframes\n",
    "#     out_df = pd.concat(df_list, axis=0)\n",
    "#     return out_df\n",
    "\n",
    "# # function to split a positive and negative dataframe into train/val/test\n",
    "# # then merge positive and negative for each\n",
    "# def split_n_dataframes(df_list, id_var: str = 'tweet_id',\n",
    "#                        test_prop: float = 0.2, seed: int = 13,\n",
    "#                        validation: bool = True, label_col: str = 'label'):\n",
    "#     # add label columns to dataframes\n",
    "#     for df_obj in df_list:\n",
    "#         df_obj.df.loc[:, 'class_label'] = df_obj.class_val\n",
    "\n",
    "#     # get empty list to put dataframe set IDs\n",
    "#     df_ids = []\n",
    "\n",
    "#     # get ids for each split dataframe\n",
    "#     for df_obj in df_list:\n",
    "#         train_ids, val_ids, test_ids = split_ids(\n",
    "#             df_obj.df[id_var],\n",
    "#             test_prop,\n",
    "#             validation,\n",
    "#             seed\n",
    "#         )\n",
    "#         df_ids.append([train_ids, val_ids, test_ids])\n",
    "\n",
    "#     # transpose list to get sublists of all train set IDs, val sets IDs, etc.\n",
    "#     trans_df_ids = [i for i in zip(*df_ids)]\n",
    "\n",
    "#     # prepare lists for indexing\n",
    "#     train_ids = trans_df_ids[0]\n",
    "#     val_ids = trans_df_ids[1]\n",
    "#     test_ids = trans_df_ids[2]\n",
    "\n",
    "#     # index split dataframes\n",
    "#     train_df = index_dataframes(df_list, train_ids, id_var)\n",
    "#     test_df = index_dataframes(df_list, test_ids, id_var)\n",
    "#     if validation:\n",
    "#         val_df = index_dataframes(df_list, val_ids, id_var)\n",
    "\n",
    "#     # shuffle dataframes\n",
    "#     train_df = train_df.sample(frac=1, random_state=seed).reset_index()\n",
    "#     test_df = test_df.sample(frac=1, random_state=seed).reset_index()\n",
    "#     if validation:\n",
    "#         val_df = val_df.sample(frac=1, random_state=seed).reset_index()\n",
    "#     else:\n",
    "#         val_df = None\n",
    "\n",
    "#     return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea3859e-0f9f-4d9a-98ab-cf6a5d684e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_negative = FrameParams(df=df[df['general_sentiment'] == -1], class_name='negative', class_val=0)\n",
    "# df_neutral = FrameParams(df=df[df['general_sentiment'] == 0], class_name='neutral', class_val=1)\n",
    "# df_positive = FrameParams(df=df[df['general_sentiment'] == 1], class_name='positive', class_val=2)\n",
    "\n",
    "# df_list = [df_negative, df_neutral, df_positive]\n",
    "# train_df, val_df, test_df = split_n_dataframes(df_list, id_var='tweet_id', test_prop=0.2, seed=13, validation=True)\n",
    "\n",
    "# print('train size:', len(train_df))\n",
    "# print('val size:', len(val_df))\n",
    "# print('test size:', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4c0fbc2-d38b-4012-884c-331aa18bed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    class is very closely based on the huggingface tutorial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, tokenizer, max_len, target_cols: list[str], id_col: str = 'row_id',\n",
    "                 text_col: str = 'TEXT'):\n",
    "        self.tokenizer = tokenizer\n",
    "        # self.data = dataframe\n",
    "        self.text_id_list = list(dataframe[id_col])\n",
    "        self.text_list = list(dataframe[text_col])\n",
    "        self.label_list = self._get_labels(dataframe, target_cols)\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def _get_labels(self, dataframe, target_col_list):\n",
    "        label_list_container = list()\n",
    "        \n",
    "        for target_col in target_col_list:\n",
    "            label_list_container.append(\n",
    "                list(dataframe[target_col])\n",
    "            )\n",
    "            \n",
    "        return list(zip(*label_list_container))\n",
    "\n",
    "    def __len__(self):\n",
    "        # get length of dataset (required for dataloader)\n",
    "        return len(self.text_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # extract text\n",
    "        text = str(self.text_list[idx])\n",
    "\n",
    "        # extract label\n",
    "        label = self.label_list[idx]\n",
    "        # print(label)\n",
    "\n",
    "        # tokenize text\n",
    "        encoded_text = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            # add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "\n",
    "        # unpack encoded text\n",
    "        ids = encoded_text['input_ids']\n",
    "        attention_mask = encoded_text['attention_mask']\n",
    "        token_type_ids = encoded_text[\"token_type_ids\"]\n",
    "\n",
    "        # wrap outputs in dict\n",
    "        out_dict = {\n",
    "            'text_id_list': self.text_id_list,\n",
    "            'id_tensor': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask_tensor': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'token_type_tensor': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'label_tensor': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "        return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97dbfd06-a278-4372-b313-f8ff26cc25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load roberta base as a tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)\n",
    "\n",
    "target_col_list = ['environment_binary', 'community_binary', 'alcohol_binary']\n",
    "\n",
    "MAX_LEN = 512\n",
    "\n",
    "# load dataframes into dataset objects\n",
    "train_ds = TextDataset(\n",
    "    dataframe=train_df, \n",
    "    tokenizer=tokenizer, \n",
    "    max_len=MAX_LEN, \n",
    "    target_cols=target_col_list\n",
    ")\n",
    "\n",
    "val_ds = TextDataset(\n",
    "    dataframe=val_df, \n",
    "    tokenizer=tokenizer, \n",
    "    max_len=MAX_LEN, \n",
    "    target_cols=target_col_list\n",
    ")\n",
    "\n",
    "test_ds = TextDataset(\n",
    "    dataframe=test_df, \n",
    "    tokenizer=tokenizer, \n",
    "    max_len=MAX_LEN, \n",
    "    target_cols=target_col_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d1b535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, batch_size, shuffle: bool = True,\n",
    "                   pin_memory: bool = True, num_workers: int = 0,\n",
    "                   prefetch_factor: int or None = None):\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=pin_memory,\n",
    "        num_workers=num_workers,\n",
    "        prefetch_factor=prefetch_factor\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# load datasets into loaders\n",
    "train_loader = get_dataloader(train_ds, BATCH_SIZE)\n",
    "val_loader = get_dataloader(val_ds, BATCH_SIZE)\n",
    "test_loader = get_dataloader(test_ds, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72fa38-6d5e-4ddd-9c48-b7ff7077f9af",
   "metadata": {},
   "source": [
    "## Instantiate RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf826146-851e-4294-aaa9-551575a84bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRoberta(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    model subclass to define the RoBERTa architecture, also closely based on\n",
    "    the huggingface tutorial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_percent, num_classes, pt_model_name: str = 'roberta-base'):\n",
    "        super().__init__()\n",
    "        self.base_model = RobertaModel.from_pretrained(pt_model_name)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(drop_percent)\n",
    "        self.classifier = torch.nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # get outputs from base model\n",
    "        base_outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        # extract hidden state from roberta base outputs\n",
    "        hidden_state = base_outputs[0]\n",
    "        x = hidden_state[:, 0]\n",
    "\n",
    "        # define the linear layer preceding the classifier\n",
    "        # and apply ReLU activation to its outputs\n",
    "        x = self.pre_classifier(x)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "\n",
    "        # define the dropout layer and classifier\n",
    "        # and apply Softmax activation to its outputs\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        # outputs = torch.nn.Softmax(dim=-1)(x)\n",
    "        return x #outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "864e1181-f162-4f0a-a1fc-308d737cd65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbrow51/.conda/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MetricCollection(\n",
       "  (acc): MultilabelAccuracy()\n",
       "  (auc): MultilabelAUROC()\n",
       "  (f1): MultilabelF1Score()\n",
       "  (prec): MultilabelPrecision()\n",
       "  (rec): MultilabelRecall()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define metric collection\n",
    "# TASK_TYPE = 'binary'\n",
    "TASK_TYPE = 'multilabel'\n",
    "NUM_CLASSES = 2\n",
    "NUM_LABELS = 3\n",
    "\n",
    "AVERAGE_STRATEGY = 'global'\n",
    "\n",
    "metric_collection = MetricCollection({\n",
    "    'acc': Accuracy(task=TASK_TYPE, num_labels=NUM_LABELS, num_classes=NUM_CLASSES, multidim_average=AVERAGE_STRATEGY),\n",
    "    'auc': AUROC(task=TASK_TYPE, num_labels=NUM_LABELS, num_classes=NUM_CLASSES),\n",
    "    'prec': Precision(task=TASK_TYPE, num_labels=NUM_LABELS, num_classes=NUM_CLASSES, multidim_average=AVERAGE_STRATEGY),\n",
    "    'rec': Recall(task=TASK_TYPE, num_labels=NUM_LABELS, num_classes=NUM_CLASSES, multidim_average=AVERAGE_STRATEGY),\n",
    "    'f1': F1Score(task=TASK_TYPE, num_labels=NUM_LABELS, num_classes=NUM_CLASSES, multidim_average=AVERAGE_STRATEGY)\n",
    "})\n",
    "\n",
    "metric_collection.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c79c0-d697-46a8-8d4c-b189f10a5b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6215060a-49a8-456c-a471-9fdbcd217144",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fdaa8a7-c591-44b1-a6e7-41c1d3a00515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# weight_tensor = torch.Tensor()\n",
    "\n",
    "model = CustomRoberta(0.5, 3)\n",
    "model.to(device)\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# define loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8fa8dd3-4f6c-44ee-a10c-08372bec09ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed set...\n",
      "\n",
      "Epoch 0 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/77 [00:01<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Long but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m loader_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: train_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m: val_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: test_loader}\n\u001b[1;32m      4\u001b[0m seed_script(SEED)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_collection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_collection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroberta-test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/NAS3/mammo/masked-roi/beatrice/datathons/duke/team-4/model/train.py:80\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(device, model, loader_dict, metric_collection, criterion, optimizer, n_epochs, save_dir, monitor_metric)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# perform train/val phases\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m phase \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 80\u001b[0m     phase_metrics_dict \u001b[38;5;241m=\u001b[39m \u001b[43mepoch_phase\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_collection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_collection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# add current phase dict to the epoch metrics object\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(epoch_metrics_object, phase, phase_metrics_dict)\n",
      "File \u001b[0;32m/mnt/NAS3/mammo/masked-roi/beatrice/datathons/duke/team-4/model/train.py:206\u001b[0m, in \u001b[0;36mepoch_phase\u001b[0;34m(phase, device, model, loader_dict, metric_collection, criterion, optimizer)\u001b[0m\n\u001b[1;32m    198\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m    199\u001b[0m     id_tensor,\n\u001b[1;32m    200\u001b[0m     mask_tensor,\n\u001b[1;32m    201\u001b[0m     token_type_tensor\n\u001b[1;32m    202\u001b[0m )\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# get the loss for the current batch preds and update\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# the running loss\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# update metric collection\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/functional.py:3127\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3124\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3125\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Long but expected Float"
     ]
    }
   ],
   "source": [
    "from model.train import train_model\n",
    "loader_dict = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "\n",
    "seed_script(SEED)\n",
    "\n",
    "train_model(\n",
    "    device=device, \n",
    "    model=model, \n",
    "    loader_dict=loader_dict, \n",
    "    metric_collection=metric_collection, \n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer, \n",
    "    n_epochs=10, \n",
    "    save_dir='roberta-test', \n",
    "    monitor_metric=\"val_loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abbf940-affa-4491-8f14-7c1eefbaa062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d7378-f861-4f5d-acbd-371cb0dff4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e252c-fbd4-4c2a-870f-12b4d75ba0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a68219-383c-491b-ace8-f61230910fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05dbcc-f3c7-4bf4-99e3-85474e42ffe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
