{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b725a9b8-d5c9-4b9d-8d87-2fbe08122cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbrow51/.conda/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tbrow51/.conda/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "import pandas as pd\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import torch\n",
    "# import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "# import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import Accuracy, AUROC, F1Score, Precision, Recall\n",
    "# from itertools import chain\n",
    "import medspacy\n",
    "from medspacy.section_detection import SectionRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f01ac45-49f0-4368-824c-803e2887a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda...\n"
     ]
    }
   ],
   "source": [
    "# get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"using device: {device}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9414f413-874b-403e-946b-6b5ea0f5dd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff49075-f477-4329-a155-afa350808b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed set...\n"
     ]
    }
   ],
   "source": [
    "def seed_script(seed: int):\n",
    "    # set torch seed\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # set numpy seed\n",
    "    np.random.seed(seed)\n",
    "    print(f\"seed set to {seed}...\")\n",
    "    \n",
    "SEED = 13\n",
    "seed_script(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861fb65-21b1-4614-a085-cec4e991854c",
   "metadata": {},
   "source": [
    "## Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5aeee7-e354-4a05-bf2b-31774a74855b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37988</td>\n",
       "      <td>Admission Date:  [**2166-6-5**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37282</td>\n",
       "      <td>Admission Date:  [**2109-12-23**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26313</td>\n",
       "      <td>Admission Date: [**2114-12-17**]        Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13852</td>\n",
       "      <td>Admission Date:  [**2112-5-16**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51031</td>\n",
       "      <td>Admission Date:  [**2155-2-26**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>7020</td>\n",
       "      <td>14096</td>\n",
       "      <td>Admission Date:  [**2136-5-6**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>7021</td>\n",
       "      <td>12564</td>\n",
       "      <td>Admission Date:  [**2152-2-28**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>7022</td>\n",
       "      <td>24492</td>\n",
       "      <td>Admission Date:  [**2146-2-7**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>7023</td>\n",
       "      <td>26304</td>\n",
       "      <td>Admission Date:  [**2167-2-10**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>7024</td>\n",
       "      <td>41160</td>\n",
       "      <td>Admission Date:  [**2105-4-28**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7025 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ROW_ID                                               TEXT\n",
       "0              0   37988  Admission Date:  [**2166-6-5**]              D...\n",
       "1              1   37282  Admission Date:  [**2109-12-23**]             ...\n",
       "2              2   26313  Admission Date: [**2114-12-17**]        Discha...\n",
       "3              3   13852  Admission Date:  [**2112-5-16**]              ...\n",
       "4              4   51031  Admission Date:  [**2155-2-26**]              ...\n",
       "...          ...     ...                                                ...\n",
       "7020        7020   14096  Admission Date:  [**2136-5-6**]       Discharg...\n",
       "7021        7021   12564  Admission Date:  [**2152-2-28**]       Dischar...\n",
       "7022        7022   24492  Admission Date:  [**2146-2-7**]              D...\n",
       "7023        7023   26304  Admission Date:  [**2167-2-10**]              ...\n",
       "7024        7024   41160  Admission Date:  [**2105-4-28**]              ...\n",
       "\n",
       "[7025 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle data import here\n",
    "train_notes_df = pd.read_csv(\"./data/df_notes.csv\")\n",
    "train_notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adcc21e8-3093-4ce5-b1b5-32482e327e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>sdoh_community_present</th>\n",
       "      <th>sdoh_community_absent</th>\n",
       "      <th>sdoh_education</th>\n",
       "      <th>sdoh_economics</th>\n",
       "      <th>sdoh_environment</th>\n",
       "      <th>behavior_alcohol</th>\n",
       "      <th>behavior_tobacco</th>\n",
       "      <th>behavior_drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>328</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>58064</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>58873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>58947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>58624</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>59236</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7025 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id  sdoh_community_present  sdoh_community_absent  sdoh_education  \\\n",
       "0          5                       0                      0               0   \n",
       "1         42                       0                      0               0   \n",
       "2        136                       1                      0               0   \n",
       "3        442                       1                      1               0   \n",
       "4        328                       1                      0               0   \n",
       "...      ...                     ...                    ...             ...   \n",
       "7020   58064                       1                      0               1   \n",
       "7021   58873                       1                      0               0   \n",
       "7022   58947                       1                      0               1   \n",
       "7023   58624                       1                      0               0   \n",
       "7024   59236                       1                      0               0   \n",
       "\n",
       "      sdoh_economics  sdoh_environment  behavior_alcohol  behavior_tobacco  \\\n",
       "0                  0                 0                 0                 1   \n",
       "1                  0                 0                 0                 2   \n",
       "2                  2                 1                 3                 4   \n",
       "3                  0                 1                 3                 1   \n",
       "4                  2                 1                 3                 3   \n",
       "...              ...               ...               ...               ...   \n",
       "7020               1                 1                 0                 0   \n",
       "7021               0                 1                 3                 3   \n",
       "7022               2                 2                 0                 0   \n",
       "7023               1                 0                 1                 2   \n",
       "7024               2                 1                 4                 2   \n",
       "\n",
       "      behavior_drug  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 2  \n",
       "4                 3  \n",
       "...             ...  \n",
       "7020              0  \n",
       "7021              3  \n",
       "7022              0  \n",
       "7023              0  \n",
       "7024              2  \n",
       "\n",
       "[7025 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset of annotations\n",
    "train_ann_url = 'https://raw.githubusercontent.com/hibaahsan/MIMIC-SBDH/main/MIMIC-SBDH.csv'\n",
    "train_ann_df = pd.read_csv(train_ann_url)\n",
    "train_ann_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a9677d-e9b4-4532-9e28-4b6e8660a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode our target variables\n",
    "alcohol_level_dict = {\n",
    "    0: 0, \n",
    "    1: 1, \n",
    "    2: 1, \n",
    "    3: 1, \n",
    "    4: 1\n",
    "}\n",
    "environment_level_dict = {\n",
    "    0: 0, \n",
    "    1: 1, \n",
    "    2: 1\n",
    "}\n",
    "\n",
    "train_set_df = train_notes_df.merge(train_ann_df, left_on=\"ROW_ID\", right_on=\"row_id\")\n",
    "train_set_df\n",
    "\n",
    "# recode the levels of 'behavior_alcohol' based on the alcohol level dict\n",
    "train_set_df.loc[:, 'alcohol_binary'] = train_set_df.loc[:, 'behavior_alcohol'].map(alcohol_level_dict)\n",
    "\n",
    "# recode the levels of 'sdoh_environment' based on the environment level dict\n",
    "train_set_df.loc[:, 'environment_binary'] = train_set_df.loc[:, 'sdoh_environment'].map(environment_level_dict)\n",
    "\n",
    "# if we have documentation of community present OR absent, code the binary version as 1 else 0\n",
    "train_set_df.loc[:, 'community_binary'] = (train_set_df.sdoh_community_present == 1) | (train_set_df.sdoh_community_absent == 1)\n",
    "train_set_df.loc[:, 'community_binary'] = train_set_df.loc[:, 'community_binary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76ad9c1-6374-421d-84f4-cc41b2e9ad47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "behavior_alcohol\n",
       "3    2444\n",
       "1    2077\n",
       "0    1657\n",
       "2     515\n",
       "4     332\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df.behavior_alcohol.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4e6c61-d0f9-4dd2-b944-b83bdffb00c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sdoh_community_present  sdoh_community_absent\n",
       "1                       0                        3878\n",
       "0                       0                        2363\n",
       "1                       1                         585\n",
       "0                       1                         199\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df[['sdoh_community_present', 'sdoh_community_absent']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4756486-9580-4e90-a901-0cb182a669d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environment_binary\n",
       "1    4420\n",
       "0    2605\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df.environment_binary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb660e9f-9e67-49b1-86e0-1c7e7eeb54e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "community_binary\n",
       "1    4662\n",
       "0    2363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df.community_binary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5524b20a-ceeb-483b-959d-e4505036ecf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol_binary\n",
       "1    5368\n",
       "0    1657\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df.alcohol_binary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a78bc55-0a98-48a5-8499-4b94f37d5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3872/7025 [23:35<20:31,  2.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admission Date:  [**2129-10-18**]     Discharge Date:  [**2129-10-22**]\n",
      "\n",
      "Date of Birth:   [**2072-10-1**]     Sex:  F\n",
      "\n",
      "Service:\n",
      "CHIEF COMPLAINT:  Pelvic organ prolapse status post\n",
      "anterior-posterior repair.\n",
      "\n",
      "HISTORY OF PRESENT ILLNESS:  This is a 56-year-old G3, P3 who\n",
      "has noticed an increasing vaginal bulge in [**Month (only) 205**] of this year.\n",
      "but did notice an increase in urinary frequency, nocturia,\n",
      "and urgency.  She had no change in her bowel habits, and is\n",
      "not sexually active.\n",
      "\n",
      "Preoperative physical examination showed a Stage II pelvic\n",
      "organ prolapse mostly cystocele.  The decision was made to\n",
      "proceed with an anterior-posterior colporrhaphy.\n",
      "PAST MEDICAL HISTORY AND PAST SURGICAL HISTORY:  Uterine\n",
      "suspension and total abdominal hysterectomy, left\n",
      "salpingo-oophorectomy in [**2106**], three right breast biopsies\n",
      "all benign, tonsil and adenoidectomy, and appendectomy,\n",
      "irritable bowel syndrome, pernicious anemia, migraine\n",
      "headaches.\n",
      "\n",
      "PAST OB HISTORY:  Three full term normal spontaneous vaginal\n",
      "deliveries.  The first one was complicated with postpartum\n",
      "hemorrhage.  Last Pap smear was [**2129-8-3**] which was\n",
      "within normal limits.\n",
      "\n",
      "PSYCHOSOCIAL HISTORY:  She denies any tobacco or alcohol use.\n",
      "\n",
      "MEDICATIONS:  Vitamin B12 q month, Fosamax 50 mg q week,\n",
      "Celexa 40 mg q day.\n",
      "\n",
      "ALLERGIES:  Penicillin, sulfa, clindamycin, and IVP dye.\n",
      "\n",
      "FAMILY HISTORY:  Mother died of breast cancer at age 52.\n",
      "Father has diabetes, heart disease, peripheral vascular\n",
      "disease.\n",
      "\n",
      "HOSPITAL COURSE:  The patient was brought to the operating\n",
      "room for same-day admission for anterior-posterior\n",
      "colporrhaphy.  The procedure was without complications, except\n",
      "for a difficult intubation. The estimated blood loss was 200 cc.\n",
      "Intraoperative findings included a Grade II-III cystocele, a\n",
      "Grade II rectocele, and a normal vaginal cuff.\n",
      "\n",
      "In the immediate postoperative period, there was noted to be\n",
      "continuous bleeding from the vagina.  Removal of the vaginal\n",
      "pack showed vigorous bleeding from two areas in the vagina\n",
      "surgical incision.  She was taken back to the operating room\n",
      "where, under a second general anesthesia, these two bleeding\n",
      "points were suture ligated with excellent hemostasis.  The\n",
      "estimated blood loss from the second procedure was 50 cc.\n",
      "\n",
      "Postoperatively, because of the difficult intubation and the\n",
      "result of pharyngeal edema, the decision was made to keep the\n",
      "patient intubated and in the MICU in order to optimize airway\n",
      "management.  The patient did well hemodynamically in the MICU\n",
      "and was extubated successfully on postoperative day one.\n",
      "\n",
      "The patient's vital signs were stable with excellent O2\n",
      "saturations.  The patient was transferred to the regular GYN\n",
      "floor on postoperative day one.  Her pain was well controlled\n",
      "with IM Demerol and was rapidly converting to po Percocet\n",
      "once the patient began tolerating a regular po diet.\n",
      "\n",
      "On postoperative day #2, the patient had a slight temperature\n",
      "elevation up to 101.9.  The patient at this time was passing\n",
      "flatus, ambulating freely, voiding spontaneously with no\n",
      "complaints of frequency.\n",
      "\n",
      "The patient had a chest x-ray was within normal limits.  She\n",
      "had a urinalysis sent which was negative and the urine\n",
      "culture was also subsequently negative.  Her white count was\n",
      "7.4.  The patient was started on Levaquin, rather than chance a\n",
      "pneumonia. The patient did\n",
      "well until the day of discharge (Levaquin day #2).  The day\n",
      "of discharge, the patient began complaining of a generalized\n",
      "rash (nonitchy).  Inspection of this rash describes the\n",
      "lesions as macular appearing rashes.\n",
      "The decision was made at this point to stop her Levaquin.  No\n",
      "additional antibiotic was started as her cultures have been\n",
      "negative to date, she has been afebrile and the white count\n",
      "was not elevated.\n",
      "\n",
      "The patient will be discharged to home with the following\n",
      "medications:  Percocet, Motrin, and Reglan.\n",
      "\n",
      "The patient's condition on discharge is good and the patient\n",
      "is discharged to home.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                          [**First Name11 (Name Pattern1) **] [**Last Name (NamePattern4) **], M.D.  [**MD Number(1) 19144**]\n",
      "\n",
      "Dictated By:[**Name8 (MD) 4872**]\n",
      "\n",
      "MEDQUIST36\n",
      "\n",
      "D:  [**2129-10-23**]  00:20\n",
      "T:  [**2129-10-26**]  11:31\n",
      "JOB#:  [**Job Number 26678**]\n",
      "\n",
      "cc:[**Last Name (NamePattern4) 26679**]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7025/7025 [42:43<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "def social_history_sectionizer(dataframe, text_col: str = 'TEXT'):\n",
    "    dataframe.loc[:, 'social_history'] = ''\n",
    "\n",
    "    # build our medspacy pipeline\n",
    "    nlp = medspacy.load()\n",
    "    sectionizer = nlp.add_pipe(\"medspacy_sectionizer\")\n",
    "    pattern_list = [\n",
    "        SectionRule(\n",
    "            category=\"social_history\", \n",
    "            literal=\"SOCIAL HISTORY:\"\n",
    "        )\n",
    "    ]\n",
    "    sectionizer.add(pattern_list)\n",
    "    \n",
    "    for i, data in tqdm(dataframe.iterrows(), total=len(dataframe)):\n",
    "        # apply the spacy pipeline to the text\n",
    "        text_sections = nlp(data[text_col])\n",
    "\n",
    "        # zip the titles and bodies together\n",
    "        title_body_zip = zip(\n",
    "            text_sections._.section_categories, \n",
    "            text_sections._.section_bodies\n",
    "        )\n",
    "\n",
    "        # extract the social history\n",
    "        soc_hist = [str(body).strip() for title, body in title_body_zip if title == \"social_history\"]\n",
    "        \n",
    "        # if a social history section was found, add it to the dataframe\n",
    "        if soc_hist:\n",
    "            dataframe.at[i, 'social_history'] = soc_hist[0]\n",
    "\n",
    "    return dataframe\n",
    "    \n",
    "train_set_df = social_history_sectionizer(train_set_df)\n",
    "# test_sections = social_history_sectionizer(train_set_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "025975f6-b039-4b92-a8d5-cb3b37db7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_df.to_csv('data/train_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b676dc3-5c05-4d1a-98f4-abb0e8d31eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>row_id</th>\n",
       "      <th>sdoh_community_present</th>\n",
       "      <th>sdoh_community_absent</th>\n",
       "      <th>sdoh_education</th>\n",
       "      <th>sdoh_economics</th>\n",
       "      <th>sdoh_environment</th>\n",
       "      <th>behavior_alcohol</th>\n",
       "      <th>behavior_tobacco</th>\n",
       "      <th>behavior_drug</th>\n",
       "      <th>alcohol_binary</th>\n",
       "      <th>environment_binary</th>\n",
       "      <th>community_binary</th>\n",
       "      <th>social_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, ROW_ID, TEXT, row_id, sdoh_community_present, sdoh_community_absent, sdoh_education, sdoh_economics, sdoh_environment, behavior_alcohol, behavior_tobacco, behavior_drug, alcohol_binary, environment_binary, community_binary, social_history]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df[pd.isnull(train_set_df.social_history)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46990180-3a6f-441f-bc45-15d6dd104e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>row_id</th>\n",
       "      <th>sdoh_community_present</th>\n",
       "      <th>sdoh_community_absent</th>\n",
       "      <th>sdoh_education</th>\n",
       "      <th>sdoh_economics</th>\n",
       "      <th>sdoh_environment</th>\n",
       "      <th>behavior_alcohol</th>\n",
       "      <th>behavior_tobacco</th>\n",
       "      <th>behavior_drug</th>\n",
       "      <th>alcohol_binary</th>\n",
       "      <th>environment_binary</th>\n",
       "      <th>community_binary</th>\n",
       "      <th>social_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37988</td>\n",
       "      <td>Admission Date:  [**2166-6-5**]              D...</td>\n",
       "      <td>37988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Lives at [**First Name4 (NamePattern1) 2299**]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37282</td>\n",
       "      <td>Admission Date:  [**2109-12-23**]             ...</td>\n",
       "      <td>37282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>She is divorced with 2 children. Recently move...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26313</td>\n",
       "      <td>Admission Date: [**2114-12-17**]        Discha...</td>\n",
       "      <td>26313</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative for alcohol. She does admit to\\nprevi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13852</td>\n",
       "      <td>Admission Date:  [**2112-5-16**]              ...</td>\n",
       "      <td>13852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>- ETOH, -Tob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51031</td>\n",
       "      <td>Admission Date:  [**2155-2-26**]              ...</td>\n",
       "      <td>51031</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Patient is single without children. She lives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>7020</td>\n",
       "      <td>14096</td>\n",
       "      <td>Admission Date:  [**2136-5-6**]       Discharg...</td>\n",
       "      <td>14096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>She denies any history of tobacco and no\\nhist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>7021</td>\n",
       "      <td>12564</td>\n",
       "      <td>Admission Date:  [**2152-2-28**]       Dischar...</td>\n",
       "      <td>12564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The patient quit smoking 40 years previous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>7022</td>\n",
       "      <td>24492</td>\n",
       "      <td>Admission Date:  [**2146-2-7**]              D...</td>\n",
       "      <td>24492</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>- Retired and lives at [**Hospital1 1426**]/[*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>7023</td>\n",
       "      <td>26304</td>\n",
       "      <td>Admission Date:  [**2167-2-10**]              ...</td>\n",
       "      <td>26304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[**1-19**] pack per day smoking history for 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>7024</td>\n",
       "      <td>41160</td>\n",
       "      <td>Admission Date:  [**2105-4-28**]              ...</td>\n",
       "      <td>41160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Occupation: supervisor at [**Last Name (un) 89...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7025 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ROW_ID                                               TEXT  \\\n",
       "0              0   37988  Admission Date:  [**2166-6-5**]              D...   \n",
       "1              1   37282  Admission Date:  [**2109-12-23**]             ...   \n",
       "2              2   26313  Admission Date: [**2114-12-17**]        Discha...   \n",
       "3              3   13852  Admission Date:  [**2112-5-16**]              ...   \n",
       "4              4   51031  Admission Date:  [**2155-2-26**]              ...   \n",
       "...          ...     ...                                                ...   \n",
       "7020        7020   14096  Admission Date:  [**2136-5-6**]       Discharg...   \n",
       "7021        7021   12564  Admission Date:  [**2152-2-28**]       Dischar...   \n",
       "7022        7022   24492  Admission Date:  [**2146-2-7**]              D...   \n",
       "7023        7023   26304  Admission Date:  [**2167-2-10**]              ...   \n",
       "7024        7024   41160  Admission Date:  [**2105-4-28**]              ...   \n",
       "\n",
       "      row_id  sdoh_community_present  sdoh_community_absent  sdoh_education  \\\n",
       "0      37988                       0                      0               0   \n",
       "1      37282                       1                      1               0   \n",
       "2      26313                       0                      0               0   \n",
       "3      13852                       0                      0               0   \n",
       "4      51031                       1                      1               0   \n",
       "...      ...                     ...                    ...             ...   \n",
       "7020   14096                       1                      0               0   \n",
       "7021   12564                       0                      0               0   \n",
       "7022   24492                       1                      0               0   \n",
       "7023   26304                       0                      0               0   \n",
       "7024   41160                       0                      0               0   \n",
       "\n",
       "      sdoh_economics  sdoh_environment  behavior_alcohol  behavior_tobacco  \\\n",
       "0                  0                 1                 2                 3   \n",
       "1                  1                 0                 2                 0   \n",
       "2                  0                 0                 3                 2   \n",
       "3                  0                 0                 1                 0   \n",
       "4                  0                 1                 0                 0   \n",
       "...              ...               ...               ...               ...   \n",
       "7020               0                 1                 3                 3   \n",
       "7021               0                 0                 0                 2   \n",
       "7022               2                 1                 1                 1   \n",
       "7023               0                 0                 1                 2   \n",
       "7024               1                 0                 0                 0   \n",
       "\n",
       "      behavior_drug  alcohol_binary  environment_binary  community_binary  \\\n",
       "0                 0               1                   1                 0   \n",
       "1                 0               1                   0                 1   \n",
       "2                 0               1                   0                 0   \n",
       "3                 0               1                   0                 0   \n",
       "4                 0               0                   1                 1   \n",
       "...             ...             ...                 ...               ...   \n",
       "7020              0               1                   1                 1   \n",
       "7021              0               0                   0                 0   \n",
       "7022              2               1                   1                 1   \n",
       "7023              3               1                   0                 0   \n",
       "7024              0               0                   0                 0   \n",
       "\n",
       "                                         social_history  \n",
       "0     Lives at [**First Name4 (NamePattern1) 2299**]...  \n",
       "1     She is divorced with 2 children. Recently move...  \n",
       "2     Negative for alcohol. She does admit to\\nprevi...  \n",
       "3                                          - ETOH, -Tob  \n",
       "4     Patient is single without children. She lives ...  \n",
       "...                                                 ...  \n",
       "7020  She denies any history of tobacco and no\\nhist...  \n",
       "7021        The patient quit smoking 40 years previous.  \n",
       "7022  - Retired and lives at [**Hospital1 1426**]/[*...  \n",
       "7023  [**1-19**] pack per day smoking history for 20...  \n",
       "7024  Occupation: supervisor at [**Last Name (un) 89...  \n",
       "\n",
       "[7025 rows x 16 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df = pd.read_csv(\"./train_sample.csv\")\n",
    "train_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad084583-b1a4-439e-a9e6-63836edc9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70/15/15 split\n",
    "# perform a split on the idxs stratified by the target classes\n",
    "# to make sure we have an even class distribution\n",
    "train_df, val_test_df = train_test_split(\n",
    "    train_set_df,\n",
    "    test_size=0.3,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    val_test_df,\n",
    "    test_size=0.5,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c3ef5f-f50b-49ea-a21f-5ca6ef2563f1",
   "metadata": {},
   "source": [
    "## Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4c0fbc2-d38b-4012-884c-331aa18bed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    class is very closely based on the huggingface tutorial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, tokenizer, max_len, target_cols: list[str], id_col: str = 'row_id',\n",
    "                 text_col: str = 'TEXT'):\n",
    "        self.tokenizer = tokenizer\n",
    "        # self.data = dataframe\n",
    "        self.text_id_list = list(dataframe[id_col])\n",
    "        self.text_list = list(dataframe[text_col])\n",
    "        self.label_list = self._get_labels(dataframe, target_cols)\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def _get_labels(self, dataframe, target_col_list):\n",
    "        label_list_container = list()\n",
    "        \n",
    "        for target_col in target_col_list:\n",
    "            label_list_container.append(\n",
    "                list(dataframe[target_col].astype(float))\n",
    "            )\n",
    "            \n",
    "        return list(zip(*label_list_container))\n",
    "\n",
    "    def __len__(self):\n",
    "        # get length of dataset (required for dataloader)\n",
    "        return len(self.text_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # extract text\n",
    "        text = str(self.text_list[idx])\n",
    "\n",
    "        # extract label\n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        # tokenize text\n",
    "        encoded_text = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            # add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "\n",
    "        # unpack encoded text\n",
    "        ids = encoded_text['input_ids']\n",
    "        attention_mask = encoded_text['attention_mask']\n",
    "        token_type_ids = encoded_text[\"token_type_ids\"]\n",
    "\n",
    "        # wrap outputs in dict\n",
    "        out_dict = {\n",
    "            'text_id_list': self.text_id_list,\n",
    "            'id_tensor': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask_tensor': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'token_type_tensor': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'label_tensor': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "        return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97dbfd06-a278-4372-b313-f8ff26cc25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load roberta base as a tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)\n",
    "\n",
    "target_col_list = ['environment_binary', 'community_binary', 'alcohol_binary']\n",
    "\n",
    "MAX_LEN = 256\n",
    "\n",
    "# load dataframes into dataset objects\n",
    "train_ds = TextDataset(\n",
    "    dataframe=train_df, \n",
    "    tokenizer=tokenizer, \n",
    "    max_len=MAX_LEN, \n",
    "    target_cols=target_col_list,\n",
    "    text_col='social_history'\n",
    ")\n",
    "\n",
    "val_ds = TextDataset(\n",
    "    dataframe=val_df, \n",
    "    tokenizer=tokenizer, \n",
    "    max_len=MAX_LEN, \n",
    "    target_cols=target_col_list,\n",
    "    text_col='social_history'\n",
    ")\n",
    "\n",
    "test_ds = TextDataset(\n",
    "    dataframe=test_df, \n",
    "    tokenizer=tokenizer, \n",
    "    max_len=MAX_LEN, \n",
    "    target_cols=target_col_list,\n",
    "    text_col='social_history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d1b535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, batch_size, shuffle: bool = True,\n",
    "                   pin_memory: bool = True, num_workers: int = 0,\n",
    "                   prefetch_factor: int or None = None):\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=pin_memory,\n",
    "        num_workers=num_workers,\n",
    "        prefetch_factor=prefetch_factor\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# load datasets into loaders\n",
    "train_loader = get_dataloader(train_ds, BATCH_SIZE)\n",
    "val_loader = get_dataloader(val_ds, BATCH_SIZE)\n",
    "test_loader = get_dataloader(test_ds, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72fa38-6d5e-4ddd-9c48-b7ff7077f9af",
   "metadata": {},
   "source": [
    "## Instantiate RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf826146-851e-4294-aaa9-551575a84bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRoberta(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    model subclass to define the RoBERTa architecture, also closely based on\n",
    "    the huggingface tutorial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_percent, num_classes, pt_model_name: str = 'roberta-base'):\n",
    "        super().__init__()\n",
    "        self.base_model = RobertaModel.from_pretrained(pt_model_name)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(drop_percent)\n",
    "        self.classifier = torch.nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # get outputs from base model\n",
    "        base_outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        # extract hidden state from roberta base outputs\n",
    "        hidden_state = base_outputs[0]\n",
    "        x = hidden_state[:, 0]\n",
    "\n",
    "        # define the linear layer preceding the classifier\n",
    "        # and apply ReLU activation to its outputs\n",
    "        x = self.pre_classifier(x)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "\n",
    "        # define the dropout layer and classifier\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "864e1181-f162-4f0a-a1fc-308d737cd65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricCollection(\n",
       "  (acc): MultilabelAccuracy()\n",
       "  (auc): MultilabelAUROC()\n",
       "  (f1): MultilabelF1Score()\n",
       "  (prec): MultilabelPrecision()\n",
       "  (rec): MultilabelRecall()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define metric collection\n",
    "# TASK_TYPE = 'binary'\n",
    "TASK_TYPE = 'multilabel'\n",
    "NUM_CLASSES = 2\n",
    "NUM_LABELS = 3\n",
    "\n",
    "AVERAGE_STRATEGY = 'global'\n",
    "\n",
    "metric_collection = MetricCollection({\n",
    "    'acc': Accuracy(task=TASK_TYPE, num_labels=NUM_LABELS, num_classes=NUM_CLASSES, multidim_average=AVERAGE_STRATEGY),\n",
    "    'auc': AUROC(task=TASK_TYPE, num_labels=NUM_LABELS, num_classes=NUM_CLASSES),\n",
    "    'prec': Precision(task=TASK_TYPE, num_labels=NUM_LABELS, num_classes=NUM_CLASSES, multidim_average=AVERAGE_STRATEGY),\n",
    "    'rec': Recall(task=TASK_TYPE, num_labels=NUM_LABELS, num_classes=NUM_CLASSES, multidim_average=AVERAGE_STRATEGY),\n",
    "    'f1': F1Score(task=TASK_TYPE, num_labels=NUM_LABELS, num_classes=NUM_CLASSES, multidim_average=AVERAGE_STRATEGY)\n",
    "})\n",
    "\n",
    "metric_collection.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c79c0-d697-46a8-8d4c-b189f10a5b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6215060a-49a8-456c-a471-9fdbcd217144",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fdaa8a7-c591-44b1-a6e7-41c1d3a00515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# weight_tensor = torch.Tensor()\n",
    "\n",
    "model = CustomRoberta(0.5, 3)\n",
    "model.to(device)\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# define loss and optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8fa8dd3-4f6c-44ee-a10c-08372bec09ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed set...\n",
      "\n",
      "Epoch 0 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([1., 1., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0., 0., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([1., 1., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:01<00:13,  1.69s/batch, train_loss=0.685, train_acc=0.552, train_auc=0.459, train_f1=0.606, train_prec=0.733, train_rec=0.516]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([1., 0., 0.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([0., 0., 1.])\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0., 0., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([0., 1., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:03<00:10,  1.57s/batch, train_loss=0.681, train_acc=0.531, train_auc=0.432, train_f1=0.612, train_prec=0.689, train_rec=0.55] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 0.])\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 0., 0.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([1., 1., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 0., 1.])\n",
      "tensor([0., 0., 1.])\n",
      "tensor([1., 0., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:04<00:16,  2.32s/batch, train_loss=0.681, train_acc=0.531, train_auc=0.432, train_f1=0.612, train_prec=0.689, train_rec=0.55]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m loader_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: train_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m: val_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: test_loader}\n\u001b[1;32m      4\u001b[0m seed_script(SEED)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_collection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_collection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroberta-test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/NAS3/mammo/masked-roi/beatrice/datathons/duke/team-4/model/train.py:80\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(device, model, loader_dict, metric_collection, criterion, optimizer, n_epochs, save_dir, monitor_metric)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# perform train/val phases\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m phase \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 80\u001b[0m     phase_metrics_dict \u001b[38;5;241m=\u001b[39m \u001b[43mepoch_phase\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_collection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_collection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# add current phase dict to the epoch metrics object\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(epoch_metrics_object, phase, phase_metrics_dict)\n",
      "File \u001b[0;32m/mnt/NAS3/mammo/masked-roi/beatrice/datathons/duke/team-4/model/train.py:214\u001b[0m, in \u001b[0;36mepoch_phase\u001b[0;34m(phase, device, model, loader_dict, metric_collection, criterion, optimizer)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# if train phase, backpropogate and step with the optimizer\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 214\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# update metrics in tqdm display after each 10% chunk\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# or if in val/test phase, update on the last batch\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from model.train import train_model\n",
    "loader_dict = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "\n",
    "seed_script(SEED)\n",
    "\n",
    "train_model(\n",
    "    device=device, \n",
    "    model=model, \n",
    "    loader_dict=loader_dict, \n",
    "    metric_collection=metric_collection, \n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer, \n",
    "    n_epochs=10, \n",
    "    save_dir='roberta-test', \n",
    "    monitor_metric=\"val_loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abbf940-affa-4491-8f14-7c1eefbaa062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d7378-f861-4f5d-acbd-371cb0dff4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e252c-fbd4-4c2a-870f-12b4d75ba0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a68219-383c-491b-ace8-f61230910fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05dbcc-f3c7-4bf4-99e3-85474e42ffe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
